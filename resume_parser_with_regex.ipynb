{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tika"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-12T06:23:01.013759Z",
          "iopub.execute_input": "2022-01-12T06:23:01.014202Z",
          "iopub.status.idle": "2022-01-12T06:23:09.672802Z",
          "shell.execute_reply.started": "2022-01-12T06:23:01.014170Z",
          "shell.execute_reply": "2022-01-12T06:23:09.671849Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnotrN8sgyis",
        "outputId": "2dbf2a18-b1b5-4dda-d935-1fab78e15679"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tika in /usr/local/lib/python3.8/dist-packages (2.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from tika) (2.25.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tika) (57.4.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->tika) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->tika) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->tika) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->tika) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tika import parser\n",
        "file = r'/content/CV-Data-scientist.pdf'\n",
        "file_data = parser.from_file(file)\n",
        "text = file_data['content']\n",
        "print(text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-12T06:23:09.674352Z",
          "iopub.execute_input": "2022-01-12T06:23:09.674802Z",
          "iopub.status.idle": "2022-01-12T06:23:09.807424Z",
          "shell.execute_reply.started": "2022-01-12T06:23:09.674751Z",
          "shell.execute_reply": "2022-01-12T06:23:09.806598Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiEjoFrEgyit",
        "outputId": "76ce1326-1734-4644-9c48-3a3855cf784b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CLAUDE EL TANNOURY\n",
            "Data scientist\n",
            "\n",
            "Elligible au CIR, trilingue et dotée d'une expérience dans le domaine du traitement\n",
            "de donnée, je cherche une opportunité dans le domaine du big data.\n",
            "\n",
            "EXPÉRIENCES\n",
            "\n",
            "Enseignante en physique\n",
            "Université d'EFREI et d'ISEP\n",
            "\n",
            "Stagiaire – Big Data & Certi�cation en Analyste Big Data\n",
            "FITEC\n",
            "\n",
            "Doctorante\n",
            "Université Rennes 1\n",
            "\n",
            "stagiaire - Géophysique\n",
            "Institut de Physique du Globe de Paris\n",
            "\n",
            "FORMATIONS\n",
            "\n",
            "Formation en Datascience\n",
            "Udemy en ligne\n",
            "\n",
            "Doctorat en Physique , Mécanismes de déclenchement\n",
            "des avalanches granulaires humides\n",
            "Université Rennes 1\n",
            "\n",
            "Master 2, Géophysique Terre Solide\n",
            "Université Paris Diderot & Institut de Physique du Globe de\n",
            "\n",
            "Paris & ENS Paris, France.\n",
            "\n",
            "Master 1, Physique Appliquée et Mécanique (parcours\n",
            "géophysiques)\n",
            "Université Paris Sud, Orsay, France.\n",
            "\n",
            "Licence, Physique\n",
            "Université Libanaise, Faculté des sciences 2, Fanar, Liban -\n",
            "\n",
            "Prix d'excellence (première de ma promotion)\n",
            "\n",
            "COORDONNÉES\n",
            "\n",
            "E-mail\n",
            "\n",
            "claudetannoury@gmail.com\n",
            "\n",
            "Adresse\n",
            "\n",
            "Avenue jeanne d'arc 94110 A\n",
            "rcueil\n",
            "\n",
            "Téléphone\n",
            "\n",
            "0635184383\n",
            "\n",
            "Lien\n",
            "\n",
            "www.linkedin.com/in/el-tan\n",
            "noury-claude-860908a7\n",
            "\n",
            "COMPÉTENCES\n",
            "\n",
            "LANGUES\n",
            "\n",
            "Français\n",
            "\n",
            "Compétence professionnelle\n",
            "complète\n",
            "\n",
            "Anglais\n",
            "\n",
            "Compétence professionnelle\n",
            "complète\n",
            "\n",
            "Arabe\n",
            "\n",
            "Compétence professionnelle\n",
            "complète\n",
            "\n",
            "Paris\n",
            "\n",
            "Septembre 2020 - Présent\n",
            "\n",
            "\n",
            "\n",
            "Paris\n",
            "\n",
            "Avril 2020 - Juillet 2020\n",
            "\n",
            "\n",
            "\n",
            "Réaliser des projets Big Data variés•\n",
            "Utiliser l'approche Agile, Interroger des sources de\n",
            "données , gérer des Bases de Donnée SQL et NoSQL,\n",
            "collecter, intégrer, stocker, gérer, analyser, traiter et\n",
            "visualiser des données et utiliser de modèles prédictifs.\n",
            "\n",
            "•\n",
            "\n",
            "Rennes\n",
            "\n",
            "Octobre 2015 - Mai 2019\n",
            "\n",
            "\n",
            "\n",
            "Plani�er et réaliser des essais expérimentaux. Analyser\n",
            "des signaux acoustiques et des images, développer des\n",
            "programmes sous Matlab.\n",
            "\n",
            "•\n",
            "\n",
            "Enseigner à l'Université Rennes 1 et encadrer des\n",
            "stagiaires.\n",
            "\n",
            "•\n",
            "\n",
            "E�ectuer une mission scienti�que à Buenos aires,\n",
            "Argentine (3 mois).\n",
            "\n",
            "•\n",
            "\n",
            "Paris\n",
            "\n",
            "2014 - 2015\n",
            "\n",
            "\n",
            "\n",
            "stage M2 (01 - 07/2015) & stage M1(03 - 07/2015)•\n",
            "Manipulation des données géophysiques, construction\n",
            "de modèle prédictif, développement des programmes\n",
            "sous bash, matlab et python.\n",
            "\n",
            "•\n",
            "\n",
            "Janvier 2020 - Mars 2020 \n",
            "\n",
            "Rennes\n",
            "\n",
            "Septembre 2015 - 2018\n",
            "\n",
            "\n",
            "\n",
            "Paris\n",
            "\n",
            "2014 - Août 2015\n",
            "\n",
            "\n",
            "\n",
            "Paris\n",
            "\n",
            "Septembre 2013 - Août 2014\n",
            "\n",
            "\n",
            "\n",
            "Liban\n",
            "\n",
            "Septembre 2010 - Août 2013\n",
            "\n",
            "\n",
            "\n",
            "Gérer un projet, travailler\n",
            "en équipe, rédiger des\n",
            "rapports de suivi et\n",
            "présenter les résultats\n",
            "\n",
            "•\n",
            "\n",
            "Réaliser du traitement des\n",
            "signaux et des images,\n",
            "analyser des données.\n",
            "\n",
            "•\n",
            "\n",
            "Maîtriser les outils : Python\n",
            "(scikit-Learn, Pandas,\n",
            "Pyspark, statsmodel,\n",
            "Numpy), Matlab, ImageJ,\n",
            "langage C, Bash, Microsoft\n",
            "O�ce, LaTeX, Linux, Trello,\n",
            "mindmup, Mural, Github,\n",
            "Talend, Hadoop, Spark\n",
            "\n",
            "•\n",
            "\n",
            "Machine Learning•\n",
            "gérer des bases de\n",
            "données SQL & No SQL\n",
            "\n",
            "•\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_text = {}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-12T06:23:09.815665Z",
          "iopub.execute_input": "2022-01-12T06:23:09.816480Z",
          "iopub.status.idle": "2022-01-12T06:23:09.827653Z",
          "shell.execute_reply.started": "2022-01-12T06:23:09.816430Z",
          "shell.execute_reply": "2022-01-12T06:23:09.826691Z"
        },
        "trusted": true,
        "id": "A4PjoKhegyiu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#E-MAIL\n",
        "import re\n",
        "def get_email_addresses(string):\n",
        "    r = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
        "    return r.findall(string)\n",
        "\n",
        "email = get_email_addresses(text)\n",
        "print(email)\n",
        "\n",
        "extracted_text[\"E-Mail\"] = email"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-12T06:23:09.830073Z",
          "iopub.execute_input": "2022-01-12T06:23:09.830848Z",
          "iopub.status.idle": "2022-01-12T06:23:09.839859Z",
          "shell.execute_reply.started": "2022-01-12T06:23:09.830808Z",
          "shell.execute_reply": "2022-01-12T06:23:09.838868Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJynCf2Lgyiv",
        "outputId": "e6202e48-91d3-4354-c90d-10d7f43b62de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['claudetannoury@gmail.com']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_phone_numbers(string):\n",
        "    r =  re.compile(r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]')\n",
        "    phone_numbers = r.findall(string)\n",
        "    return [re.sub(r'\\D', '', num) for num in phone_numbers]\n",
        "\n",
        "phone_number= get_phone_numbers(text)\n",
        "print(phone_number)\n",
        "\n",
        "extracted_text[\"Phone Number\"] = phone_number"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-12T06:23:09.841057Z",
          "iopub.execute_input": "2022-01-12T06:23:09.841410Z",
          "iopub.status.idle": "2022-01-12T06:23:09.851975Z",
          "shell.execute_reply.started": "2022-01-12T06:23:09.841380Z",
          "shell.execute_reply": "2022-01-12T06:23:09.851310Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfySqpE-gyiv",
        "outputId": "9a045c90-7421-452b-ae26-0109366118c6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['20142015', '20107', '20152018']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nlp"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-12T06:23:09.853160Z",
          "iopub.execute_input": "2022-01-12T06:23:09.853587Z",
          "iopub.status.idle": "2022-01-12T06:23:18.479908Z",
          "shell.execute_reply.started": "2022-01-12T06:23:09.853556Z",
          "shell.execute_reply": "2022-01-12T06:23:18.478814Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1pMGRkagyiw",
        "outputId": "07f4ff90-7f01-4733-808a-577fe348d7ae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nlp in /usr/local/lib/python3.8/dist-packages (0.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from nlp) (2.25.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from nlp) (1.3.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from nlp) (0.3.6)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.8/dist-packages (from nlp) (9.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from nlp) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from nlp) (3.9.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from nlp) (4.64.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from nlp) (3.2.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->nlp) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->nlp) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->nlp) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->nlp) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->nlp) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->nlp) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->nlp) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Name\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# load pre-trained model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# initialize matcher with a vocab\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "def extract_name(resume_text):\n",
        "    nlp_text = nlp(resume_text)\n",
        "    \n",
        "    # First name and Last name are always Proper Nouns\n",
        "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'},{'POS': 'PROPN'}]\n",
        "    \n",
        "    matcher.add('NAME', [pattern], on_match = None)\n",
        "    \n",
        "    matches = matcher(nlp_text)\n",
        "    \n",
        "    for match_id, start, end in matches:\n",
        "        span = nlp_text[start:end]\n",
        "        return span.text\n",
        "    \n",
        "    \n",
        "name = extract_name(text)\n",
        "print(name)\n",
        "extracted_text[\"Name\"] = name"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-12T06:23:18.481770Z",
          "iopub.execute_input": "2022-01-12T06:23:18.482047Z",
          "iopub.status.idle": "2022-01-12T06:23:19.342603Z",
          "shell.execute_reply.started": "2022-01-12T06:23:18.482013Z",
          "shell.execute_reply": "2022-01-12T06:23:19.341623Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfJMVWW6gyix",
        "outputId": "c3eb5818-bbbd-49f5-f111-5500bdfac0d4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLAUDE EL TANNOURY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s553O4AH-1ZU",
        "outputId": "919dd9d6-b196-4d29-d6bf-00b703128971"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import spacy\n",
        "\n",
        "# load pre-trained model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "\n",
        "def extract_skills(resume_text):\n",
        "    nlp_text = nlp(resume_text)\n",
        "\n",
        "    # removing stop words and implementing word tokenization\n",
        "    tokens = [token.text for token in nlp_text if not token.is_stop]\n",
        "    skills = [\"python\", \"numpy\", \"pandas\",\"scikit-learn\", \"keras\", \"flask\",\"machine learning\",\"deep learning\",\"c++\",\n",
        "             \"matlab\",\n",
        "             \"html\",\n",
        "             \"github\",\n",
        "             \"php\"]\n",
        "    \n",
        "    skillset = []\n",
        "    \n",
        "    # check for bi-grams and tri-grams (example: machine learning)\n",
        "    for token in nlp_text.noun_chunks:\n",
        "        token = token.text.lower().strip()\n",
        "        if token in skills:\n",
        "            skillset.append(token)\n",
        "    \n",
        "    return [i.capitalize() for i in set([i.lower() for i in skillset])]\n",
        "\n",
        "skills = []\n",
        "skills = extract_skills(text)\n",
        "\n",
        "extracted_text[\"Skills\"] = skills\n",
        "skills "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-12T06:23:19.346324Z",
          "iopub.execute_input": "2022-01-12T06:23:19.346679Z",
          "iopub.status.idle": "2022-01-12T06:23:20.203466Z",
          "shell.execute_reply.started": "2022-01-12T06:23:19.346614Z",
          "shell.execute_reply": "2022-01-12T06:23:20.202533Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fae_mQ_Pgyiy",
        "outputId": "5519a0f9-8487-4dac-cde8-fdc3856e4a3d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Numpy', 'Github', 'Pandas', 'Matlab', 'Python']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-12T06:23:21.377483Z",
          "iopub.execute_input": "2022-01-12T06:23:21.378450Z",
          "iopub.status.idle": "2022-01-12T06:23:21.384805Z",
          "shell.execute_reply.started": "2022-01-12T06:23:21.378411Z",
          "shell.execute_reply": "2022-01-12T06:23:21.383730Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSF9KxRegyi0",
        "outputId": "997886aa-b240-413a-859f-2f91b0ff22cb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'E-Mail': ['claudetannoury@gmail.com'],\n",
              " 'Phone Number': ['20142015', '20107', '20152018'],\n",
              " 'Name': 'CLAUDE EL TANNOURY',\n",
              " 'Skills': ['Numpy', 'Github', 'Pandas', 'Matlab', 'Python']}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}